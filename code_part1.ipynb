{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This notebook implements the object tracking algorithm based on Harris corner detection\n",
    "and basic Lucas Kanade optic flow.'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_derivative(img1, img2):\n",
    "    \n",
    "    dx1 = cv2.Sobel(img1,cv2.CV_64F,1,0,ksize=3)\n",
    "    dy1 = cv2.Sobel(img1,cv2.CV_64F,0,1,ksize=3)\n",
    "    dx2 = cv2.Sobel(img2,cv2.CV_64F,1,0,ksize=3)\n",
    "    dy2 = cv2.Sobel(img2,cv2.CV_64F,0,1,ksize=3)\n",
    "    ix = (dx1 + dx2) / 2\n",
    "    iy = (dy1 + dy2) / 2\n",
    "    \n",
    "    sigma = 1.0\n",
    "    k = cv2.getGaussianKernel(9, sigma)\n",
    "    g = k * np.transpose(k)\n",
    "    imgFiltered1 = cv2.filter2D(img1, -1, g)\n",
    "    imgFiltered2 = cv2.filter2D(img2, -1, g)\n",
    "    it = imgFiltered1 - imgFiltered2\n",
    "    \n",
    "    return ix, iy, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harris_corner(img):\n",
    "    ix = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
    "    iy = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
    "    \n",
    "    k = 0.05\n",
    "    sigma = 1.0\n",
    "    g = cv2.getGaussianKernel(3, sigma)\n",
    "    G = g * np.transpose(g)\n",
    "    sum_filter = np.ones((3, 3))\n",
    "    ixx = cv2.filter2D(ix**2, -1, G)\n",
    "    iyy = cv2.filter2D(iy**2, -1, G)\n",
    "    ixy = cv2.filter2D(ix*iy, -1, G)\n",
    "    sxx = cv2.filter2D(ixx, -1, sum_filter)\n",
    "    syy = cv2.filter2D(iyy, -1, sum_filter)\n",
    "    sxy = cv2.filter2D(ixy, -1, sum_filter)\n",
    "    det = sxx*syy-sxy**2\n",
    "    trace = sxx + syy\n",
    "    response = det - k*(trace**2)\n",
    "    max_response = np.max(response)\n",
    "    features = np.where(response>=1e-1*max_response)\n",
    "    filtered_x = []\n",
    "    filtered_y = []\n",
    "    for i in range(len(features[0])):\n",
    "        if i==0:\n",
    "            filtered_x.append(features[0][i])\n",
    "            filtered_y.append(features[1][i])\n",
    "        else:\n",
    "            bound = 0 if len(filtered_x)<=20 else (len(filtered_x)-20)\n",
    "            flag = True\n",
    "            for j in range(bound, len(filtered_x)):\n",
    "                d = (features[0][i]-filtered_x[j])**2 + (features[1][i]-filtered_y[j])**2\n",
    "                if d<=100:\n",
    "                    flag = False\n",
    "            if flag:\n",
    "                filtered_x.append(features[0][i])\n",
    "                filtered_y.append(features[1][i])\n",
    "    return (np.array(filtered_x), np.array(filtered_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LK_optic_flow(img1, img2, features=None):\n",
    "    U = []\n",
    "    V = []\n",
    "    U_map = np.zeros(img1.shape)\n",
    "    V_map = np.zeros(img1.shape)\n",
    "    window_size = (5, 5)\n",
    "    sum_kernel = np.ones(window_size)\n",
    "    ix, iy, it = cal_derivative(img1, img2)\n",
    "#     six = cv2.filter2D(ix, -1, sum_kernel)\n",
    "#     siy = cv2.filter2D(iy, -1, sum_kernel)\n",
    "#     sit = cv2.filter2D(it, -1, sum_kernel)\n",
    "    \n",
    "    if features is None:\n",
    "        features = harris_corner(img1)\n",
    "        \n",
    "    for i in range(len(features[0])):\n",
    "        center_x, center_y = features[0][i], features[1][i]\n",
    "        offset_x = int(((window_size[1]-1)/2))\n",
    "        offset_y = int(((window_size[0]-1)/2))\n",
    "        if center_x < offset_x:\n",
    "            center_x = offset_x\n",
    "        if center_x > img1.shape[1] - (offset_x+1):\n",
    "            center_x = img1.shape[1] - offset_x\n",
    "        if center_y < offset_y:\n",
    "            center_y = offset_y\n",
    "        if center_y >img1.shape[0] - (offset_y+1):\n",
    "            center_y = img1.shape[0] - offset_y\n",
    "#         print(center_x-offset_x, center_x+offset_x, center_y-offset_y, center_y+offset_y)\n",
    "        pix = ix[int(center_x-offset_x):int(center_x+offset_x), int(center_y-offset_y):int(center_y+offset_y)]\n",
    "        piy = iy[int(center_x-offset_x):int(center_x+offset_x), int(center_y-offset_y):int(center_y+offset_y)]\n",
    "        pit = it[int(center_x-offset_x):int(center_x+offset_x), int(center_y-offset_y):int(center_y+offset_y)]\n",
    "        X = np.reshape(pix, (1, -1)).squeeze()\n",
    "        Y = np.reshape(piy, (1, -1)).squeeze()\n",
    "        b = np.reshape(pit, (1, -1)).squeeze()\n",
    "        AT = np.array([X, Y])\n",
    "        A = np.transpose(AT)\n",
    "        ATA = np.matmul(AT, A)\n",
    "        ATb = np.matmul(AT, b)\n",
    "        ATA_inv = np.linalg.pinv(ATA)\n",
    "        x = np.matmul(ATA_inv, ATb)\n",
    "        U.append(x[0])\n",
    "        V.append(x[1])\n",
    "        \n",
    "    for i in range(len(features[0])):\n",
    "        U_map[features[0][i], features[1][i]] = U[i]\n",
    "        V_map[features[0][i], features[1][i]] = V[i]\n",
    "        \n",
    "    return features, U_map, V_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(features, u, v):\n",
    "    # normalization\n",
    "#     u[np.where(u==0)] = 1e-5\n",
    "#     v[np.where(v==0)] = 1e-5\n",
    "    threshold = 1e-3\n",
    "    for i in range(u.shape[0]):\n",
    "        for j in range(u.shape[1]):\n",
    "            if u[i, j] > threshold:\n",
    "                u[i, j] = 1\n",
    "            elif u[i, j] < -threshold:\n",
    "                u[i, j] = -1\n",
    "            else:\n",
    "                u[i, j] = 0\n",
    "            if v[i, j] > threshold:\n",
    "                v[i, j] = 1\n",
    "            elif v[i, j] < -threshold:\n",
    "                v[i, j] = -1\n",
    "            else:\n",
    "                v[i, j] = 0\n",
    "    \n",
    "    new_xs = []\n",
    "    new_ys = []\n",
    "    for i in range(len(features[0])):\n",
    "#         print(i, features[0][i], features[1][i], u[features[0][i]][features[1][i]], v[features[0][i]][features[1][i]])\n",
    "        new_x = features[0][i] + v[features[0][i]][features[1][i]]\n",
    "        new_y = features[1][i] + u[features[0][i]][features[1][i]]\n",
    "        if new_x >= u.shape[0]:\n",
    "            new_x = u.shape[0]-1\n",
    "        if new_y >= u.shape[1]:\n",
    "            new_y = u.shape[1]-1\n",
    "        new_xs.append(int(new_x))\n",
    "        new_ys.append(int(new_y))\n",
    "        \n",
    "    return (new_xs, new_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_record()->str:\n",
    "    #call the camera of the computer\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    #set the output Parameters\n",
    "    out = cv2.VideoWriter('recording.avi', fourcc, 30.0, (640,480))\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame=cap.read()\n",
    "        if ret==True:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            out.write(frame)\n",
    "            cv2.imshow('frame', frame)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return 'recording.avi'\n",
    "\n",
    "cap = cv2.VideoCapture(\"demo7.mp4\")\n",
    "\n",
    "# random colors for plotting\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# feature extraction\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = harris_corner(old_gray)\n",
    "\n",
    "# Create a mask image for plotting\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret,frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # calculate optical flow\n",
    "    p1, u, v = LK_optic_flow(old_gray, frame_gray, p0)\n",
    "    p1 = estimate(p1, u, v)\n",
    "\n",
    "    # plottings\n",
    "    for i in range(len(p1[0])):\n",
    "        a,b = p1[1][i], p1[0][i]\n",
    "        c,d = p0[1][i], p0[0][i]\n",
    "        mask = cv2.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "    cv2.imshow('frame',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # update features and frames\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = p1\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
